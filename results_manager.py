"""
Results Management Module for Dynamic Reactor Ramp Analysis
==========================================================

Handles results comparison, data export, and file management.
Separated from main analysis for modularity and easier maintenance.

Author: Seonggyun Kim (seonggyun.kim@outlook.com)
Date: August 2025
"""

import os
import pandas as pd
import numpy as np
import shutil
from typing import Dict, Any, Optional, List

class ResultsComparison:
    """Handles creation and updating of results comparison file"""
    
    COMPARISON_FILE = "Ramp_Analysis_Results_Comparison.csv"
    
    @staticmethod
    def update_comparison_file(metrics: Dict[str, Any], scenario_name: str = None, output_dir: str = None) -> str:
        """Update or create the results comparison file"""
        
        if output_dir is None:
            output_dir = os.getcwd()
        
        comparison_file_path = os.path.join(output_dir, ResultsComparison.COMPARISON_FILE)
        
        # Create a unique column name based on ramp parameters only
        duration = metrics['Ramp_Duration']['value']
        direction = metrics['Ramp_Direction']['value'] 
        curve_type = metrics['Ramp_Curve_Type']['value']
        
        # Handle N/A values
        duration_str = f"{duration}min" if duration != 'N/A' else 'NoRamp'
        direction_str = direction if direction != 'N/A' else 'none'
        curve_str = curve_type if curve_type != 'N/A' else 'none'
        
        column_name = f"{duration_str}_{direction_str}_{curve_str}"
        
        # Prepare data for the new column (values only, but include source file for timestamp extraction)
        new_data_values = {}
        new_data_units = {}
        for key, data in metrics.items():
            new_data_values[key] = data['value']
            new_data_units[key] = data['unit']
        
        # Check if file exists
        if os.path.exists(comparison_file_path):
            try:
                df_existing = pd.read_csv(comparison_file_path, index_col=0, comment='#')
                print(f"Loaded existing comparison file with {len(df_existing.columns)} columns")
            except Exception as e:
                print(f"Error reading existing file: {e}")
                df_existing = pd.DataFrame()
        else:
            df_existing = pd.DataFrame()
            print("Creating new comparison file")
        
        # Create new dataframe with the new column
        df_new_column = pd.DataFrame(new_data_values, index=[column_name]).T
        
        # Combine with existing data
        if not df_existing.empty:
            # Remove existing column if it exists (overwrite mode)
            if column_name in df_existing.columns:
                df_existing = df_existing.drop(columns=[column_name])
                print(f"Overwriting existing column: {column_name}")
            
            # Combine data
            df_combined = pd.concat([df_existing, df_new_column], axis=1, sort=False)
            
            # Handle Units column properly
            if 'Units' in df_combined.columns:
                # Update existing Units column with new units
                for metric, unit in new_data_units.items():
                    if metric in df_combined.index:
                        df_combined.loc[metric, 'Units'] = unit
            else:
                # Add Units column for the first time - create it as a proper column
                units_series = pd.Series(new_data_units, name='Units')
                df_combined = pd.concat([df_combined, units_series], axis=1, sort=False)
        else:
            # First entry - create both data and units columns
            units_series = pd.Series(new_data_units, name='Units')
            df_combined = pd.concat([df_new_column, units_series], axis=1, sort=False)
        
        # Save to file
        try:
            df_combined.to_csv(comparison_file_path, encoding='utf-8')
            print(f"Updated comparison file: {comparison_file_path}")
            print(f"Total columns: {len(df_combined.columns)}")
            
            # Add metadata header comment
            with open(comparison_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            header_comment = f"""# Ramp Analysis Results Comparison
# Generated by Dynamic Reactor Ramp Analysis Tool
# Last updated: {pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")}
# 
# Each column represents one ramp test configuration: Duration_Direction_CurveType
# Each row represents a key metric from the analysis
# Units column shows the measurement units for each metric
# Same ramp configurations will overwrite previous results
#
"""
            
            with open(comparison_file_path, 'w', encoding='utf-8') as f:
                f.write(header_comment + content)
            
        except Exception as e:
            print(f"Error saving comparison file: {e}")
            return "Error"
        
        return column_name

class DataExporter:
    """Handles saving analysis results and data structures"""
    
    @staticmethod
    def save_data_structure(data_package: Dict[str, Any], output_dir: Optional[str] = None) -> str:
        """Save the parsed data structure to files"""
        if output_dir is None:
            base_csv_name = os.path.splitext(os.path.basename(data_package['file_path']))[0]
            output_dir = os.path.join(os.getcwd(), f"{base_csv_name}_ramp_analysis")
        
        os.makedirs(output_dir, exist_ok=True)
        print(f"\nCreated ramp analysis folder: {output_dir}")
        
        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
        base_filename = os.path.splitext(os.path.basename(data_package['file_path']))[0]
        
        # Save vectors
        time_file = os.path.join(output_dir, f"{base_filename}_time_vector_{timestamp}.csv")
        length_file = os.path.join(output_dir, f"{base_filename}_length_vector_{timestamp}.csv")
        
        pd.Series(data_package['time_vector']).to_csv(time_file, encoding='utf-8', index=False, header=['Time_min'])
        pd.Series(data_package['length_vector']).to_csv(length_file, encoding='utf-8', index=False, header=['Position_m'])
        
        # Save matrices for each variable
        for var_name, matrix in data_package['variables'].items():
            clean_name = var_name.replace(" ", "_").replace("/", "_")
            matrix_file = os.path.join(output_dir, f"{base_filename}_{clean_name}_matrix_{timestamp}.csv")
            
            df_matrix = pd.DataFrame(
                matrix,
                index=[f"t_{t:.3f}" for t in data_package['time_vector']],
                columns=[f"pos_{p:.3f}" for p in data_package['length_vector']]
            )
            df_matrix.to_csv(matrix_file, encoding='utf-8')
        
        # Save summary info
        summary_file = os.path.join(output_dir, f"{base_filename}_ramp_data_summary_{timestamp}.txt")
        with open(summary_file, 'w') as f:
            f.write("=== Aspen Plus Ramp Data Parsing Summary ===\n\n")
            f.write(f"Source file: {data_package['file_path']}\n")
            f.write(f"Parsing timestamp: {timestamp}\n\n")
            f.write(f"Dimensions:\n")
            f.write(f"  Time points (n): {data_package['dimensions']['n_time']}\n")
            f.write(f"  Length points (m): {data_package['dimensions']['m_length']}\n\n")
            f.write(f"Time range: {data_package['time_vector'].min():.3f} - {data_package['time_vector'].max():.3f} min\n")
            f.write(f"Length range: {data_package['length_vector'].min():.3f} - {data_package['length_vector'].max():.3f} m\n\n")
            f.write(f"Variables parsed:\n")
            for var_name, matrix in data_package['variables'].items():
                valid_data = ~np.isnan(matrix)
                data_range = matrix[valid_data]
                if len(data_range) > 0:
                    f.write(f"  {var_name}: {data_range.min():.3e} to {data_range.max():.3e}\n")
                else:
                    f.write(f"  {var_name}: No valid data\n")
        
        return timestamp
    
    @staticmethod
    def save_plots(plots, output_dir: Optional[str] = None, file_prefix: str = "analysis") -> List[str]:
        """Save generated plots to files"""
        if output_dir is None:
            output_dir = os.getcwd()
        
        os.makedirs(output_dir, exist_ok=True)
        saved_files = []
        
        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
        
        for plot_name, fig in plots:
            # Create safe filename
            safe_name = plot_name.replace(" ", "_").replace("/", "_").replace("\\", "_")
            filename = f"{file_prefix}_{safe_name}_{timestamp}.png"
            filepath = os.path.join(output_dir, filename)
            
            try:
                fig.savefig(filepath, dpi=300, bbox_inches='tight', facecolor='white')
                saved_files.append(filepath)
                print(f"Saved plot: {filename}")
            except Exception as e:
                print(f"Error saving plot {plot_name}: {e}")
        
        return saved_files

class ConfigManager:
    """Manages analysis configuration and settings"""
    
    DEFAULT_CONFIG = {
        'steady_state': {
            'threshold': 0.05,
            'min_duration': 10,
            'window_size': 20
        },
        'plotting': {
            'style': 'seaborn-v0_8',
            'palette': 'viridis',
            'figure_size': {
                'temperature_response': (16, 6),
                'stability_analysis': (12, 8),
                'spatial_gradients': (20, 12),
                'heat_transfer_3d': (14, 10)
            }
        },
        'analysis': {
            'default_time_limit': None,
            'auto_detect_ramp': True,
            'zone_analysis_count': 5
        }
    }
    
    @classmethod
    def get_config(cls, section: str = None) -> Dict[str, Any]:
        """Get configuration settings"""
        if section is None:
            return cls.DEFAULT_CONFIG
        return cls.DEFAULT_CONFIG.get(section, {})
    
    @classmethod
    def update_matplotlib_settings(cls):
        """Update matplotlib settings based on configuration"""
        import matplotlib.pyplot as plt
        import seaborn as sns
        
        config = cls.get_config('plotting')
        plt.style.use(config.get('style', 'seaborn-v0_8'))
        sns.set_palette(config.get('palette', 'viridis'))


class AnalysisReporter:
    """Handles generation of analysis reports and summaries"""
    
    @staticmethod
    def print_analysis_summary(data_package: Dict[str, Any], ramp_params: Any, 
                             steady_state_time: Optional[float], stability_metrics: Dict[str, Any]):
        """Print a comprehensive analysis summary"""
        print("\n" + "="*60)
        print("ANALYSIS SUMMARY")
        print("="*60)
        
        # File information
        if 'source_file' in data_package:
            print(f"Source File: {os.path.basename(data_package['source_file'])}")
        
        # Ramp parameters
        print(f"\nRamp Parameters:")
        if hasattr(ramp_params, 'duration') and ramp_params.duration:
            print(f"   Duration: {ramp_params.duration} minutes")
            print(f"   Direction: {ramp_params.direction}")
            print(f"   Curve Type: {ramp_params.curve_shape}")
            print(f"   Start Time: {ramp_params.start_time} min")
        else:
            print("   No ramp detected")
        
        # Steady state information
        print(f"\nSteady State Analysis:")
        if steady_state_time:
            print(f"   Steady state achieved at: {steady_state_time:.1f} minutes")
        else:
            print("   No steady state detected in analysis period")
        
        # Stability metrics
        if stability_metrics:
            print(f"\nStability Metrics:")
            for metric, value in stability_metrics.items():
                if isinstance(value, (int, float)):
                    print(f"   {metric}: {value:.3f}")
                else:
                    print(f"   {metric}: {value}")
        
        # Variable summary
        variables = data_package.get('variables', {})
        if variables:
            print(f"\nVariables Analyzed: {len(variables)}")
            for var_name in list(variables.keys())[:5]:  # Show first 5
                print(f"   • {var_name}")
            if len(variables) > 5:
                print(f"   ... and {len(variables) - 5} more")
        
        print("="*60)


class DataUtilities:
    """Utility functions for data processing and formatting"""
    
    @staticmethod
    def extract_timestamp_from_column(column_name):
        """Extract timestamp from column name with format like '20-down-s-20250801-231457'"""
        import re
        try:
            # Pattern to match YYYYMMDD-HHMMSS at the end of the column name
            pattern = r'(\d{8})-(\d{6})(?:\.csv)?$'
            match = re.search(pattern, column_name)
            
            if match:
                date_part = match.group(1)  # YYYYMMDD
                time_part = match.group(2)  # HHMMSS
                
                # Convert to readable format
                year = date_part[:4]
                month = date_part[4:6]
                day = date_part[6:8]
                
                hour = time_part[:2]
                minute = time_part[2:4]
                second = time_part[4:6]
                
                formatted_date = f"{year}-{month}-{day}"
                formatted_time = f"{hour}:{minute}:{second}"
                
                return formatted_date, formatted_time
            else:
                # Fallback: check if column name looks like a file path or has identifiable patterns
                if '.csv' in column_name.lower() or '\\' in column_name or '/' in column_name:
                    # Extract just the filename if it's a full path
                    filename = column_name.split('\\')[-1].split('/')[-1]
                    # Try pattern matching on the filename
                    pattern_match = re.search(r'(\d{8})-(\d{6})', filename)
                    if pattern_match:
                        date_part = pattern_match.group(1)
                        time_part = pattern_match.group(2)
                        
                        year = date_part[:4]
                        month = date_part[4:6]
                        day = date_part[6:8]
                        hour = time_part[:2]
                        minute = time_part[2:4]
                        second = time_part[4:6]
                        
                        return f"{year}-{month}-{day}", f"{hour}:{minute}:{second}"
                
                # Final fallback: return column name truncated for date and N/A for time
                return column_name[:10] if len(column_name) >= 10 else column_name, "N/A"
                
        except Exception:
            # Fallback: return column name for date and N/A for time
            return column_name[:10] if len(column_name) >= 10 else column_name, "N/A"
    
    @staticmethod
    def format_for_display(value, metric_name=None):
        """Format values for display with special handling for specific metrics"""
        try:
            # Handle special metric types with specific value conversions
            if metric_name == 'Ramp_Curve_Type':
                # Convert curve codes to display names: s -> Sinusoidal, r -> Linear
                if value == 's':
                    return 'Sinusoidal'
                elif value == 'r':
                    return 'Linear'
                else:
                    return str(value) if value not in ['', 'N/A', '-'] else value
            
            elif metric_name == 'Ramp_Direction':
                # Convert direction codes to display names: d -> Down, u -> Up, down -> Down, up -> Up
                if value in ['d', 'down']:
                    return 'Down'
                elif value in ['u', 'up']:
                    return 'Up'
                else:
                    return str(value) if value not in ['', 'N/A', '-'] else value
            
            # Handle empty values first
            if pd.isna(value) or value == '' or str(value).strip() == '':
                return ''
            
            # Handle 'N/A' and similar string values
            if isinstance(value, str) and value.strip().lower() in ['n/a', 'na', 'nan', 'none', '-']:
                return value
            
            # Try to convert to float for numeric formatting
            num_value = float(value)
            
            # Handle zero
            if num_value == 0:
                return '0'
            
            # Format to 5 significant figures
            # Use scientific notation for very large or very small numbers
            abs_value = abs(num_value)
            if abs_value >= 1e6 or abs_value < 1e-3:
                # Scientific notation with 4 decimal places (5 sig figs total)
                formatted = f"{num_value:.4e}"
            else:
                # Determine number of decimal places needed for 5 sig figs
                if abs_value >= 1:
                    # For numbers >= 1, decimal places = 5 - number of digits before decimal
                    digits_before_decimal = len(str(int(abs_value)))
                    decimal_places = max(0, 5 - digits_before_decimal)
                    formatted = f"{num_value:.{decimal_places}f}"
                else:
                    # For numbers < 1, use g format which handles sig figs well
                    formatted = f"{num_value:.4g}"
            
            # Clean up trailing zeros for non-scientific notation
            if 'e' not in formatted.lower():
                formatted = formatted.rstrip('0').rstrip('.')
            
            return formatted
            
        except (ValueError, TypeError):
            # If conversion fails, return original value as string
            return str(value)
    
    @staticmethod
    def curve_code_to_display(curve_code):
        """Convert curve code to display name (s -> Sinusoidal, r -> Linear)"""
        if curve_code == 's':
            return 'Sinusoidal'
        elif curve_code == 'r':
            return 'Linear'
        else:
            return curve_code
    
    @staticmethod
    def curve_display_to_code(curve_display):
        """Convert display name to curve code (Sinusoidal -> s, Linear -> r)"""
        if curve_display == 'Sinusoidal':
            return 's'
        elif curve_display == 'Linear':
            return 'r'
        else:
            return curve_display
