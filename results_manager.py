"""
Results Management Module for Dynamic Reactor Ramp Analysis
==========================================================

Handles results comparison, data export, and file management.
Separated from main analysis for modularity and easier maintenance.

Author: Seonggyun Kim (seonggyun.kim@outlook.com)
Date: August 2025
"""

import os
import pandas as pd
import numpy as np
import shutil
from typing import Dict, Any, Optional, List

class ResultsComparison:
    """Handles creation and updating of results comparison file"""
    
    COMPARISON_FILE = "Ramp_Analysis_Results_Comparison.csv"
    
    @staticmethod
    def update_comparison_file(metrics: Dict[str, Any], scenario_name: str = None, output_dir: str = None) -> str:
        """Update or create the results comparison file"""
        
        if output_dir is None:
            output_dir = os.getcwd()
        
        comparison_file_path = os.path.join(output_dir, ResultsComparison.COMPARISON_FILE)
        
        # Create a unique column name based on ramp parameters only
        duration = metrics['Ramp_Duration']['value']
        direction = metrics['Ramp_Direction']['value'] 
        curve_type = metrics['Ramp_Curve_Type']['value']
        
        # Handle N/A values
        duration_str = f"{duration}min" if duration != 'N/A' else 'NoRamp'
        direction_str = direction if direction != 'N/A' else 'none'
        curve_str = curve_type if curve_type != 'N/A' else 'none'
        
        column_name = f"{duration_str}_{direction_str}_{curve_str}"
        
        # Prepare data for the new column (values only, but include source file for timestamp extraction)
        new_data_values = {}
        new_data_units = {}
        for key, data in metrics.items():
            new_data_values[key] = data['value']
            new_data_units[key] = data['unit']
        
        # Check if file exists
        if os.path.exists(comparison_file_path):
            try:
                df_existing = pd.read_csv(comparison_file_path, index_col=0, comment='#')
                print(f"Loaded existing comparison file with {len(df_existing.columns)} columns")
            except Exception as e:
                print(f"Error reading existing file: {e}")
                df_existing = pd.DataFrame()
        else:
            df_existing = pd.DataFrame()
            print("Creating new comparison file")
        
        # Create new dataframe with the new column
        df_new_column = pd.DataFrame(new_data_values, index=[column_name]).T
        
        # Combine with existing data
        if not df_existing.empty:
            # Remove existing column if it exists (overwrite mode)
            if column_name in df_existing.columns:
                df_existing = df_existing.drop(columns=[column_name])
                print(f"Overwriting existing column: {column_name}")
            
            # Combine data
            df_combined = pd.concat([df_existing, df_new_column], axis=1, sort=False)
            
            # Handle Units column properly
            if 'Units' in df_combined.columns:
                # Update existing Units column with new units
                for metric, unit in new_data_units.items():
                    if metric in df_combined.index:
                        df_combined.loc[metric, 'Units'] = unit
            else:
                # Add Units column for the first time - create it as a proper column
                units_series = pd.Series(new_data_units, name='Units')
                df_combined = pd.concat([df_combined, units_series], axis=1, sort=False)
        else:
            # First entry - create both data and units columns
            units_series = pd.Series(new_data_units, name='Units')
            df_combined = pd.concat([df_new_column, units_series], axis=1, sort=False)
        
        # Save to file
        try:
            df_combined.to_csv(comparison_file_path)
            print(f"Updated comparison file: {comparison_file_path}")
            print(f"Total columns: {len(df_combined.columns)}")
            
            # Add metadata header comment
            with open(comparison_file_path, 'r') as f:
                content = f.read()
            
            header_comment = f"""# Ramp Analysis Results Comparison
# Generated by Dynamic Reactor Ramp Analysis Tool
# Last updated: {pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")}
# 
# Each column represents one ramp test configuration: Duration_Direction_CurveType
# Each row represents a key metric from the analysis
# Units column shows the measurement units for each metric
# Same ramp configurations will overwrite previous results
#
"""
            
            with open(comparison_file_path, 'w') as f:
                f.write(header_comment + content)
            
        except Exception as e:
            print(f"Error saving comparison file: {e}")
            return "Error"
        
        return column_name

class DataExporter:
    """Handles saving analysis results and data structures"""
    
    @staticmethod
    def save_data_structure(data_package: Dict[str, Any], output_dir: Optional[str] = None) -> str:
        """Save the parsed data structure to files"""
        if output_dir is None:
            base_csv_name = os.path.splitext(os.path.basename(data_package['file_path']))[0]
            output_dir = os.path.join(os.getcwd(), f"{base_csv_name}_ramp_analysis")
        
        os.makedirs(output_dir, exist_ok=True)
        print(f"\nCreated ramp analysis folder: {output_dir}")
        
        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
        base_filename = os.path.splitext(os.path.basename(data_package['file_path']))[0]
        
        # Save vectors
        time_file = os.path.join(output_dir, f"{base_filename}_time_vector_{timestamp}.csv")
        length_file = os.path.join(output_dir, f"{base_filename}_length_vector_{timestamp}.csv")
        
        pd.Series(data_package['time_vector']).to_csv(time_file, index=False, header=['Time_min'])
        pd.Series(data_package['length_vector']).to_csv(length_file, index=False, header=['Position_m'])
        
        # Save matrices for each variable
        for var_name, matrix in data_package['variables'].items():
            clean_name = var_name.replace(" ", "_").replace("/", "_")
            matrix_file = os.path.join(output_dir, f"{base_filename}_{clean_name}_matrix_{timestamp}.csv")
            
            df_matrix = pd.DataFrame(
                matrix,
                index=[f"t_{t:.3f}" for t in data_package['time_vector']],
                columns=[f"pos_{p:.3f}" for p in data_package['length_vector']]
            )
            df_matrix.to_csv(matrix_file)
        
        # Save summary info
        summary_file = os.path.join(output_dir, f"{base_filename}_ramp_data_summary_{timestamp}.txt")
        with open(summary_file, 'w') as f:
            f.write("=== Aspen Plus Ramp Data Parsing Summary ===\n\n")
            f.write(f"Source file: {data_package['file_path']}\n")
            f.write(f"Parsing timestamp: {timestamp}\n\n")
            f.write(f"Dimensions:\n")
            f.write(f"  Time points (n): {data_package['dimensions']['n_time']}\n")
            f.write(f"  Length points (m): {data_package['dimensions']['m_length']}\n\n")
            f.write(f"Time range: {data_package['time_vector'].min():.3f} - {data_package['time_vector'].max():.3f} min\n")
            f.write(f"Length range: {data_package['length_vector'].min():.3f} - {data_package['length_vector'].max():.3f} m\n\n")
            f.write(f"Variables parsed:\n")
            for var_name, matrix in data_package['variables'].items():
                valid_data = ~np.isnan(matrix)
                data_range = matrix[valid_data]
                if len(data_range) > 0:
                    f.write(f"  {var_name}: {data_range.min():.3e} to {data_range.max():.3e}\n")
                else:
                    f.write(f"  {var_name}: No valid data\n")
        
        return timestamp
    
    @staticmethod
    def save_plots(plots, output_dir: Optional[str] = None, file_prefix: str = "analysis") -> List[str]:
        """Save generated plots to files"""
        if output_dir is None:
            output_dir = os.getcwd()
        
        os.makedirs(output_dir, exist_ok=True)
        saved_files = []
        
        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
        
        for plot_name, fig in plots:
            # Create safe filename
            safe_name = plot_name.replace(" ", "_").replace("/", "_").replace("\\", "_")
            filename = f"{file_prefix}_{safe_name}_{timestamp}.png"
            filepath = os.path.join(output_dir, filename)
            
            try:
                fig.savefig(filepath, dpi=300, bbox_inches='tight', facecolor='white')
                saved_files.append(filepath)
                print(f"Saved plot: {filename}")
            except Exception as e:
                print(f"Error saving plot {plot_name}: {e}")
        
        return saved_files

class ConfigManager:
    """Manages analysis configuration and settings"""
    
    DEFAULT_CONFIG = {
        'steady_state': {
            'threshold': 0.05,
            'min_duration': 10,
            'window_size': 20
        },
        'plotting': {
            'style': 'seaborn-v0_8',
            'palette': 'viridis',
            'figure_size': {
                'temperature_response': (16, 6),
                'stability_analysis': (12, 8),
                'spatial_gradients': (20, 12),
                'heat_transfer_3d': (14, 10)
            }
        },
        'analysis': {
            'default_time_limit': None,
            'auto_detect_ramp': True,
            'zone_analysis_count': 5
        }
    }
    
    @classmethod
    def get_config(cls, section: str = None) -> Dict[str, Any]:
        """Get configuration settings"""
        if section is None:
            return cls.DEFAULT_CONFIG
        return cls.DEFAULT_CONFIG.get(section, {})
    
    @classmethod
    def update_matplotlib_settings(cls):
        """Update matplotlib settings based on configuration"""
        import matplotlib.pyplot as plt
        import seaborn as sns
        
        config = cls.get_config('plotting')
        plt.style.use(config.get('style', 'seaborn-v0_8'))
        sns.set_palette(config.get('palette', 'viridis'))


class AnalysisReporter:
    """Handles generation of analysis reports and summaries"""
    
    @staticmethod
    def print_analysis_summary(data_package: Dict[str, Any], ramp_params: Any, 
                             steady_state_time: Optional[float], stability_metrics: Dict[str, Any]):
        """Print a comprehensive analysis summary"""
        print("\n" + "="*60)
        print("ANALYSIS SUMMARY")
        print("="*60)
        
        # File information
        if 'source_file' in data_package:
            print(f"Source File: {os.path.basename(data_package['source_file'])}")
        
        # Ramp parameters
        print(f"\nRamp Parameters:")
        if hasattr(ramp_params, 'duration') and ramp_params.duration:
            print(f"   Duration: {ramp_params.duration} minutes")
            print(f"   Direction: {ramp_params.direction}")
            print(f"   Curve Type: {ramp_params.curve_shape}")
            print(f"   Start Time: {ramp_params.start_time} min")
        else:
            print("   No ramp detected")
        
        # Steady state information
        print(f"\nSteady State Analysis:")
        if steady_state_time:
            print(f"   Steady state achieved at: {steady_state_time:.1f} minutes")
        else:
            print("   No steady state detected in analysis period")
        
        # Stability metrics
        if stability_metrics:
            print(f"\nStability Metrics:")
            for metric, value in stability_metrics.items():
                if isinstance(value, (int, float)):
                    print(f"   {metric}: {value:.3f}")
                else:
                    print(f"   {metric}: {value}")
        
        # Variable summary
        variables = data_package.get('variables', {})
        if variables:
            print(f"\nVariables Analyzed: {len(variables)}")
            for var_name in list(variables.keys())[:5]:  # Show first 5
                print(f"   • {var_name}")
            if len(variables) > 5:
                print(f"   ... and {len(variables) - 5} more")
        
        print("="*60)
